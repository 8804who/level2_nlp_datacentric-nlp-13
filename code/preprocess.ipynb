{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = '/opt/ml/data/'\n",
    "random.seed(42)\n",
    "data = pd.read_csv(DATA_DIR+'/train.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove any character that is not an uppercase letter, lowercase letter, digit, or Korean, or Chinese characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = set()\n",
    "special = re.compile(r'[^ A-Za-z0-9가-힣一-龥]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_data = pd.read_csv('/opt/ml/data/noise_data.csv')\n",
    "denoised_data = pd.read_csv('/opt/ml/data/denoised_text.csv')\n",
    "original_text = pd.read_csv('/opt/ml/data/original_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoise_and_noise=denoised_data.copy()\n",
    "for data in noise_data.itertuples():\n",
    "    prob = random.uniform(0, 1)\n",
    "    if prob >= 0.6:\n",
    "        denoise_and_noise=pd.concat([denoise_and_noise, pd.DataFrame({'ID':[data.ID],'text':[data.text],'target':[data.target], 'url':[data.url],'date':[data.date]})], ignore_index=True)\n",
    "denoise_and_noise = denoise_and_noise.drop_duplicates(['ID'], keep='last')\n",
    "denoise_and_noise = denoise_and_noise.sample(frac=1).reset_index(drop=True)\n",
    "denoise_and_noise.to_csv('/opt/ml/data/denoised_text+noise.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for text in original_text.text:\n",
    "    texts.append(special.sub('',text))\n",
    "\n",
    "original_text_no_special = pd.DataFrame({'ID':original_text.ID,'text':texts,'target':original_text.target, 'url':original_text.url,'date':original_text.date})\n",
    "original_text_no_special.to_csv('/opt/ml/data/original_text_no_special.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stopwords and punctuation from the chatGPT augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "augData=pd.read_csv('../data/aug_data.csv')\n",
    "for i in range(len(augData)):\n",
    "    line=augData.loc[i,'text'].replace('\"','').replace('...',',').replace('..',',').replace('..',',').replace('·',',')\n",
    "    line=re.sub(\"(ㆍ|…)\",',',line)\n",
    "    line=re.sub(\"(‘|’|')\",\"\",line)\n",
    "    line=re.sub(\" 등 \",\" \",line)\n",
    "    augData.loc[i,'text']=line\n",
    "\n",
    "augData.to_csv(\"augData_news.csv\",index=False)   \n",
    "augData.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stopwords and punctuation from the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noNoise=pd.read_csv('./no_noise_data.csv')\n",
    "\n",
    "#drop columns except text and target \n",
    "noNoise=noNoise.drop(columns=['url','date','ID','Unnamed: 0'])\n",
    "for i in range(len(noNoise)):\n",
    "    line=noNoise.loc[i,'text'].replace('...','').replace('·',',')\n",
    "    line=re.sub(\"(종합| 등 |게시판 |종합2보|…)\",\" \",line)\n",
    "    noNoise.loc[i,'text']=line\n",
    "    \n",
    "noNoise.to_csv(\"news_pre.csv\",index=False)\n",
    "noNoise.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other replaceable words and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#line=re.sub(\"↑\",\" 증가\",line)\n",
    "#line=line.replace('中','중국 ')\n",
    "#line=line.replace('美','미국 ')\n",
    "#line=line.replace('韓','한국 ')\n",
    "#line=line.replace('北','북한 ')\n",
    "#line=line.replace('日','일본 ')\n",
    "#line=line.replace('英','영국 ')\n",
    "#line=re.sub(\"(종합| 등 |게시판 |종합|종합2보|…| 첫 |역대 | 새 | 연속 |작년 |올해 |최대 )\",\" \",line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
